<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<title>AR_EXAMPLE — Face Filter (Stable Bundle)</title>
<style>
  html, body { margin:0; padding:0; background:#000; height:100%; overflow:hidden; font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; }
  #stage { position:fixed; inset:0; }
  video, canvas { position:absolute; top:0; left:0; width:100%; height:100%; object-fit:cover; transform: scaleX(-1); }
  #ui { position:fixed; inset:0; display:flex; align-items:center; justify-content:center; color:#fff; background:#000; z-index:10; }
  #ui.hide { display:none; }
  button { padding:12px 16px; border-radius:12px; border:0; background:#1f6feb; color:#fff; font-size:16px; margin:6px; }
  #log { position:fixed; left:8px; top:8px; color:#0f0; font:12px ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; z-index:20; white-space:pre-wrap; max-width:90vw; }
  .wm { position:fixed; right:8px; bottom:8px; color:#fff9; font:12px ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }
</style>
<!-- Load the stable global bundle that exposes FaceLandmarker & FilesetResolver on window -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.js" crossorigin="anonymous"></script>
</head>
<body>
  <div id="ui">
    <div style="text-align:center">
      <h2>Face Filter</h2>
      <p>1) Try <b>Camera Test</b> to confirm permissions. 2) Tap <b>Start Face Filter</b>.</p>
      <div>
        <button id="test">Camera Test</button>
        <button id="start">Start Face Filter</button>
      </div>
      <p style="opacity:.7;font-size:12px;margin-top:8px">If it seems cached, add <code>?v=5</code> to the URL and reload.</p>
    </div>
  </div>
  <div id="log"></div>
  <div class="wm">AR_EXAMPLE</div>
  <div id="stage">
    <video id="video" playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>

<script>
  const logEl = document.getElementById('log');
  const log = (s)=> logEl.textContent = String(s ?? '');

  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');
  const stage = document.getElementById('stage');
  function fit(){ canvas.width = stage.clientWidth; canvas.height = stage.clientHeight; }
  window.addEventListener('resize', fit);

  async function cameraTest(){
    try{
      fit();
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio:false });
      video.srcObject = stream; await video.play();
      log('Camera OK — you should see video. Now press "Start Face Filter".');
    }catch(e){
      alert('Camera error: ' + e.message);
    }
  }

  function rrRect(x,y,w,h,r){
    r = Math.min(r, w/2, h/2);
    ctx.beginPath();
    ctx.moveTo(x+r,y);
    ctx.arcTo(x+w,y,x+w,y+h,r);
    ctx.arcTo(x+w,y+h,x,y+h,r);
    ctx.arcTo(x,y+h,x,y,r);
    ctx.arcTo(x,y,x+w,y,r);
    ctx.closePath();
    ctx.fill();
  }
  function drawGlasses(landmarks) {
    const W = canvas.width, H = canvas.height;
    const toXY = p => ({ x: (1 - p.x) * W, y: p.y * H });

    const L = toXY(landmarks[263]), LI = toXY(landmarks[362]);
    const R = toXY(landmarks[33]),  RI = toXY(landmarks[133]);
    const leftC = { x:(L.x+LI.x)/2, y:(L.y+LI.y)/2 };
    const rightC= { x:(R.x+RI.x)/2, y:(R.y+RI.y)/2 };
    const dx = leftC.x - rightC.x, dy = leftC.y - rightC.y;
    const angle = Math.atan2(dy, dx);
    const eyeDist = Math.hypot(dx, dy);
    const lensW = eyeDist * 0.55, lensH = eyeDist * 0.32, bridgeW = eyeDist * 0.18;
    const rim = Math.max(2, Math.round(lensH * 0.12));
    const mid = { x:(leftC.x+rightC.x)/2, y:(leftC.y+rightC.y)/2 };
    const halfGap = bridgeW/2, lensGap = halfGap + lensW/2;

    ctx.save();
    ctx.translate(mid.x, mid.y);
    ctx.rotate(angle);

    ctx.fillStyle = 'rgba(15,15,15,0.94)';
    const rr = lensH*0.25;
    rrRect(-lensGap - lensW/2, -lensH/2, lensW, lensH, rr);
    rrRect(lensGap - lensW/2, -lensH/2, lensW, lensH, rr);

    ctx.fillStyle='rgba(20,20,20,0.95)';
    rrRect(-halfGap, -lensH*0.18, bridgeW, lensH*0.36, lensH*0.18);

    ctx.strokeStyle='rgba(10,10,10,0.9)';
    ctx.lineWidth=Math.max(2, rim*0.6);
    const armLen=lensW*0.9;
    ctx.beginPath();
    ctx.moveTo(-lensGap - lensW/2, -lensH*0.15); ctx.lineTo(-lensGap - lensW/2 - armLen, -lensH*0.15);
    ctx.moveTo(lensGap + lensW/2, -lensH*0.15);  ctx.lineTo(lensGap + lensW/2 + armLen, -lensH*0.15);
    ctx.stroke();

    ctx.restore();
  }

  let loopId = null;
  async function startFilter(){
    try{
      document.getElementById('ui').classList.add('hide');
      fit();
      if (!video.srcObject){
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user', width:{ideal:1280}, height:{ideal:720} }, audio:false });
        video.srcObject = stream; await video.play();
      }
      log('Loading face model...');
      // vision_bundle.js exposes global constructors: FilesetResolver and FaceLandmarker
      if (typeof FilesetResolver === 'undefined' || typeof FaceLandmarker === 'undefined'){
        alert('Face model bundle not loaded. Check network or ad-blocker.');
        return;
      }
      const fileset = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );
      const faceLandmarker = await FaceLandmarker.createFromOptions(fileset, {
        baseOptions: { modelAssetPath: "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm/face_landmarker.task" },
        runningMode: "VIDEO",
        numFaces: 1
      });
      log('Model loaded. Tracking...');

      function frame(){
        const ts = Date.now();
        const result = faceLandmarker.detectForVideo(video, ts);
        ctx.clearRect(0,0,canvas.width,canvas.height);
        if (result && result.faceLandmarks && result.faceLandmarks.length){
          drawGlasses(result.faceLandmarks[0]);
          log('');
        } else {
          log('no face');
        }
        loopId = requestAnimationFrame(frame);
      }
      if (loopId) cancelAnimationFrame(loopId);
      frame();
    }catch(e){
      alert('Start failed: ' + e.message);
    }
  }

  document.getElementById('test').addEventListener('click', cameraTest);
  document.getElementById('start').addEventListener('click', startFilter);
</script>
</body>
</html>
